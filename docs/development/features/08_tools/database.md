# üóÑÔ∏è Database Management Tools

> **Advanced Database Administration JA-CMS**  
> Comprehensive database tools dengan optimization, monitoring, dan maintenance capabilities

---

## üìã **Deskripsi**

Database Management Tools menyediakan comprehensive database administration untuk JA-CMS dengan database optimization, performance monitoring, maintenance automation, query analysis, dan backup/restore capabilities untuk memastikan optimal database performance dan data integrity.

---

## ‚≠ê **Core Features**

### **1. üöÄ Database Optimization Engine**

#### **Optimization Architecture:**
```typescript
interface DatabaseOptimizationSystem {
  optimizers: DatabaseOptimizer[];
  analyzers: PerformanceAnalyzer[];
  indexManagers: IndexManager[];
  queryOptimizers: QueryOptimizer[];
  maintenanceScheduler: MaintenanceScheduler;
  monitoringService: DatabaseMonitoringService;
  reportGenerator: OptimizationReportGenerator;
}

interface DatabaseOptimizer {
  id: string;
  name: string;
  description: string;
  category: OptimizationCategory;
  enabled: boolean;
  config: OptimizerConfig;
  schedule?: OptimizationSchedule;
  thresholds: OptimizationThresholds;
  dependencies: string[];
  rollback: RollbackConfig;
}

interface OptimizationJob {
  id: string;
  name: string;
  type: OptimizationType;
  targets: OptimizationTarget[];
  status: JobStatus;
  progress: OptimizationProgress;
  results: OptimizationResult;
  recommendations: Recommendation[];
  beforeSnapshot: DatabaseSnapshot;
  afterSnapshot?: DatabaseSnapshot;
  rollbackData?: RollbackData;
  startedAt: Date;
  completedAt?: Date;
  duration?: number;
  createdBy: string;
}

interface DatabaseAnalysis {
  timestamp: Date;
  databaseInfo: DatabaseInfo;
  tableAnalysis: TableAnalysis[];
  indexAnalysis: IndexAnalysis[];
  queryAnalysis: QueryAnalysis[];
  performanceMetrics: PerformanceMetrics;
  storageAnalysis: StorageAnalysis;
  recommendations: AnalysisRecommendation[];
  healthScore: number;
}

interface TableAnalysis {
  tableName: string;
  schema: string;
  rowCount: number;
  dataSize: number;
  indexSize: number;
  totalSize: number;
  avgRowLength: number;
  autoIncrement?: number;
  collation: string;
  engine: string;
  fragmentation: number;
  lastOptimized?: Date;
  columns: ColumnInfo[];
  indexes: IndexInfo[];
  foreignKeys: ForeignKeyInfo[];
  constraints: ConstraintInfo[];
  statistics: TableStatistics;
}

interface IndexAnalysis {
  indexName: string;
  tableName: string;
  indexType: IndexType;
  columns: string[];
  unique: boolean;
  cardinality: number;
  size: number;
  usage: IndexUsage;
  fragmentation: number;
  effectiveness: number;
  recommendations: IndexRecommendation[];
}

type OptimizationCategory = 'performance' | 'storage' | 'maintenance' | 'security' | 'backup';
type OptimizationType = 'table_optimization' | 'index_optimization' | 'query_optimization' | 'storage_cleanup' | 'maintenance';
type JobStatus = 'pending' | 'analyzing' | 'optimizing' | 'completed' | 'failed' | 'cancelled';
type IndexType = 'primary' | 'unique' | 'index' | 'fulltext' | 'spatial';
```

#### **Database Optimization Service:**
```typescript
export class DatabaseOptimizationService {
  private optimizers: Map<OptimizationType, DatabaseOptimizer>;
  private analyzers: Map<string, PerformanceAnalyzer>;
  private indexManager: IndexManager;
  private queryOptimizer: QueryOptimizer;
  private maintenanceScheduler: MaintenanceScheduler;
  private monitoringService: DatabaseMonitoringService;
  private rollbackManager: RollbackManager;

  async analyzeDatabase(): Promise<DatabaseAnalysis> {
    const analysis: DatabaseAnalysis = {
      timestamp: new Date(),
      databaseInfo: await this.getDatabaseInfo(),
      tableAnalysis: [],
      indexAnalysis: [],
      queryAnalysis: [],
      performanceMetrics: await this.getPerformanceMetrics(),
      storageAnalysis: await this.getStorageAnalysis(),
      recommendations: [],
      healthScore: 0
    };

    try {
      // Analyze all tables
      const tables = await this.getAllTables();
      for (const table of tables) {
        const tableAnalysis = await this.analyzeTable(table);
        analysis.tableAnalysis.push(tableAnalysis);

        // Analyze table indexes
        for (const index of tableAnalysis.indexes) {
          const indexAnalysis = await this.analyzeIndex(index, table);
          analysis.indexAnalysis.push(indexAnalysis);
        }
      }

      // Analyze slow queries
      analysis.queryAnalysis = await this.analyzeSlowQueries();

      // Generate recommendations
      analysis.recommendations = await this.generateOptimizationRecommendations(analysis);

      // Calculate health score
      analysis.healthScore = this.calculateDatabaseHealthScore(analysis);

    } catch (error) {
      console.error('Database analysis failed:', error);
      throw error;
    }

    return analysis;
  }

  async optimizeDatabase(optimizationConfig: OptimizationConfig): Promise<OptimizationJob> {
    const job: OptimizationJob = {
      id: this.generateJobId(),
      name: optimizationConfig.name || 'Database Optimization',
      type: optimizationConfig.type,
      targets: optimizationConfig.targets,
      status: 'pending',
      progress: this.initializeProgress(),
      results: this.initializeResults(),
      recommendations: [],
      beforeSnapshot: await this.createDatabaseSnapshot(),
      startedAt: new Date(),
      createdBy: optimizationConfig.createdBy
    };

    try {
      job.status = 'analyzing';
      
      // Pre-optimization analysis
      const preAnalysis = await this.analyzeDatabase();
      job.recommendations = preAnalysis.recommendations;

      // Create rollback point if configured
      if (optimizationConfig.createRollbackPoint) {
        const rollbackData = await this.rollbackManager.createRollbackPoint('database_optimization');
        job.rollbackData = rollbackData;
      }

      job.status = 'optimizing';

      // Execute optimization based on type
      const optimizationResult = await this.executeOptimization(job.type, job.targets, optimizationConfig);
      
      job.results = optimizationResult;
      job.afterSnapshot = await this.createDatabaseSnapshot();
      job.status = 'completed';
      job.completedAt = new Date();
      job.duration = job.completedAt.getTime() - job.startedAt.getTime();

      // Generate optimization report
      const report = await this.generateOptimizationReport(job);
      job.results.report = report;

    } catch (error) {
      job.status = 'failed';
      job.results = {
        ...job.results,
        success: false,
        error: error.message
      };

      // Attempt rollback if configured
      if (job.rollbackData && optimizationConfig.rollbackOnFailure) {
        try {
          await this.rollbackManager.rollback(job.rollbackData.id);
          job.results.rolledBack = true;
        } catch (rollbackError) {
          console.error('Rollback failed:', rollbackError);
        }
      }
    }

    return job;
  }

  private async executeOptimization(
    type: OptimizationType,
    targets: OptimizationTarget[],
    config: OptimizationConfig
  ): Promise<OptimizationResult> {
    const result: OptimizationResult = {
      success: false,
      operations: [],
      improvements: [],
      warnings: [],
      statistics: {
        tablesOptimized: 0,
        indexesOptimized: 0,
        spaceSaved: 0,
        performanceImprovement: 0
      }
    };

    switch (type) {
      case 'table_optimization':
        return await this.optimizeTables(targets, config);
      case 'index_optimization':
        return await this.optimizeIndexes(targets, config);
      case 'query_optimization':
        return await this.optimizeQueries(targets, config);
      case 'storage_cleanup':
        return await this.cleanupStorage(targets, config);
      case 'maintenance':
        return await this.performMaintenance(targets, config);
      default:
        throw new Error(`Unknown optimization type: ${type}`);
    }
  }

  private async optimizeTables(targets: OptimizationTarget[], config: OptimizationConfig): Promise<OptimizationResult> {
    const result: OptimizationResult = {
      success: false,
      operations: [],
      improvements: [],
      warnings: [],
      statistics: {
        tablesOptimized: 0,
        indexesOptimized: 0,
        spaceSaved: 0,
        performanceImprovement: 0
      }
    };

    try {
      for (const target of targets) {
        if (target.type === 'table') {
          const tableResult = await this.optimizeTable(target.name, config);
          
          result.operations.push({
            type: 'table_optimization',
            target: target.name,
            success: tableResult.success,
            details: tableResult.details,
            spaceSaved: tableResult.spaceSaved,
            duration: tableResult.duration
          });

          if (tableResult.success) {
            result.statistics.tablesOptimized++;
            result.statistics.spaceSaved += tableResult.spaceSaved;
          }

          result.improvements.push(...tableResult.improvements);
          result.warnings.push(...tableResult.warnings);
        }
      }

      result.success = result.operations.every(op => op.success);

    } catch (error) {
      result.success = false;
      result.error = error.message;
    }

    return result;
  }

  private async optimizeTable(tableName: string, config: OptimizationConfig): Promise<TableOptimizationResult> {
    const result: TableOptimizationResult = {
      success: false,
      details: {},
      spaceSaved: 0,
      duration: 0,
      improvements: [],
      warnings: []
    };

    const startTime = Date.now();

    try {
      // Get table info before optimization
      const beforeInfo = await this.getTableInfo(tableName);
      
      // Optimize table
      await this.executeQuery(`OPTIMIZE TABLE ${tableName}`);
      
      // Get table info after optimization
      const afterInfo = await this.getTableInfo(tableName);
      
      // Calculate improvements
      result.spaceSaved = beforeInfo.dataSize + beforeInfo.indexSize - (afterInfo.dataSize + afterInfo.indexSize);
      result.duration = Date.now() - startTime;
      
      result.details = {
        before: beforeInfo,
        after: afterInfo,
        operations: ['OPTIMIZE TABLE']
      };

      result.improvements.push({
        type: 'space_optimization',
        description: `Saved ${this.formatBytes(result.spaceSaved)} of disk space`,
        impact: 'positive'
      });

      // Check for fragmentation improvement
      const fragmentationImprovement = beforeInfo.fragmentation - afterInfo.fragmentation;
      if (fragmentationImprovement > 0) {
        result.improvements.push({
          type: 'fragmentation_reduction',
          description: `Reduced fragmentation by ${fragmentationImprovement.toFixed(2)}%`,
          impact: 'positive'
        });
      }

      result.success = true;

    } catch (error) {
      result.success = false;
      result.error = error.message;
      result.duration = Date.now() - startTime;
    }

    return result;
  }

  private async optimizeIndexes(targets: OptimizationTarget[], config: OptimizationConfig): Promise<OptimizationResult> {
    const result: OptimizationResult = {
      success: false,
      operations: [],
      improvements: [],
      warnings: [],
      statistics: {
        tablesOptimized: 0,
        indexesOptimized: 0,
        spaceSaved: 0,
        performanceImprovement: 0
      }
    };

    try {
      for (const target of targets) {
        if (target.type === 'table') {
          // Get table indexes
          const indexes = await this.getTableIndexes(target.name);
          
          for (const index of indexes) {
            const indexResult = await this.optimizeIndex(index, config);
            
            result.operations.push({
              type: 'index_optimization',
              target: `${target.name}.${index.indexName}`,
              success: indexResult.success,
              details: indexResult.details,
              spaceSaved: indexResult.spaceSaved,
              duration: indexResult.duration
            });

            if (indexResult.success) {
              result.statistics.indexesOptimized++;
              result.statistics.spaceSaved += indexResult.spaceSaved;
            }

            result.improvements.push(...indexResult.improvements);
            result.warnings.push(...indexResult.warnings);
          }
        }
      }

      result.success = result.operations.every(op => op.success);

    } catch (error) {
      result.success = false;
      result.error = error.message;
    }

    return result;
  }

  private async optimizeIndex(index: IndexInfo, config: OptimizationConfig): Promise<IndexOptimizationResult> {
    const result: IndexOptimizationResult = {
      success: false,
      details: {},
      spaceSaved: 0,
      duration: 0,
      improvements: [],
      warnings: []
    };

    const startTime = Date.now();

    try {
      // Analyze index usage
      const usage = await this.getIndexUsage(index.indexName, index.tableName);
      
      // Check if index should be dropped (unused)
      if (usage.selectCount === 0 && usage.insertCount === 0 && usage.updateCount === 0) {
        if (config.removeUnusedIndexes && !index.unique && index.indexType !== 'primary') {
          await this.dropIndex(index.indexName, index.tableName);
          
          result.spaceSaved = index.size;
          result.improvements.push({
            type: 'unused_index_removal',
            description: `Removed unused index ${index.indexName}`,
            impact: 'positive'
          });
        } else {
          result.warnings.push({
            type: 'unused_index',
            description: `Index ${index.indexName} appears to be unused`,
            recommendation: 'Consider removing if not needed'
          });
        }
      }

      // Check index fragmentation
      if (index.fragmentation > config.indexFragmentationThreshold) {
        await this.rebuildIndex(index.indexName, index.tableName);
        
        result.improvements.push({
          type: 'index_defragmentation',
          description: `Rebuilt fragmented index ${index.indexName}`,
          impact: 'positive'
        });
      }

      result.duration = Date.now() - startTime;
      result.success = true;

    } catch (error) {
      result.success = false;
      result.error = error.message;
      result.duration = Date.now() - startTime;
    }

    return result;
  }

  async repairDatabase(repairConfig: RepairConfig): Promise<RepairResult> {
    const result: RepairResult = {
      success: false,
      operations: [],
      repairedTables: [],
      corruptedTables: [],
      warnings: []
    };

    try {
      // Check all tables for corruption
      const tables = await this.getAllTables();
      
      for (const table of tables) {
        const checkResult = await this.checkTable(table);
        
        if (checkResult.status === 'corrupt') {
          result.corruptedTables.push({
            tableName: table,
            issues: checkResult.issues,
            severity: checkResult.severity
          });

          // Attempt repair
          if (repairConfig.autoRepair) {
            const repairResult = await this.repairTable(table, repairConfig);
            
            result.operations.push({
              type: 'table_repair',
              target: table,
              success: repairResult.success,
              details: repairResult.details
            });

            if (repairResult.success) {
              result.repairedTables.push(table);
            }
          }
        }
      }

      result.success = result.corruptedTables.length === 0 || result.repairedTables.length === result.corruptedTables.length;

    } catch (error) {
      result.success = false;
      result.error = error.message;
    }

    return result;
  }

  private async checkTable(tableName: string): Promise<TableCheckResult> {
    try {
      const checkQuery = `CHECK TABLE ${tableName}`;
      const results = await this.executeQuery(checkQuery);
      
      const status = results[0]?.Msg_text?.toLowerCase();
      
      if (status?.includes('ok')) {
        return {
          tableName,
          status: 'ok',
          issues: [],
          severity: 'none'
        };
      } else if (status?.includes('warning')) {
        return {
          tableName,
          status: 'warning',
          issues: [status],
          severity: 'low'
        };
      } else {
        return {
          tableName,
          status: 'corrupt',
          issues: [status || 'Unknown corruption'],
          severity: 'high'
        };
      }

    } catch (error) {
      return {
        tableName,
        status: 'error',
        issues: [error.message],
        severity: 'high'
      };
    }
  }

  private async repairTable(tableName: string, config: RepairConfig): Promise<TableRepairResult> {
    const result: TableRepairResult = {
      success: false,
      details: {},
      duration: 0
    };

    const startTime = Date.now();

    try {
      // Try REPAIR TABLE first
      const repairQuery = `REPAIR TABLE ${tableName}`;
      const repairResults = await this.executeQuery(repairQuery);
      
      const repairStatus = repairResults[0]?.Msg_text?.toLowerCase();
      
      if (repairStatus?.includes('ok')) {
        result.success = true;
        result.details = {
          method: 'REPAIR TABLE',
          result: repairStatus
        };
      } else if (config.useMyISAMChk) {
        // Try myisamchk for MyISAM tables
        const myisamResult = await this.repairWithMyISAMChk(tableName);
        result.success = myisamResult.success;
        result.details = {
          method: 'myisamchk',
          result: myisamResult.output
        };
      }

    } catch (error) {
      result.success = false;
      result.details = {
        error: error.message
      };
    } finally {
      result.duration = Date.now() - startTime;
    }

    return result;
  }
}

interface OptimizationResult {
  success: boolean;
  operations: OptimizationOperation[];
  improvements: Improvement[];
  warnings: Warning[];
  statistics: OptimizationStatistics;
  error?: string;
  report?: OptimizationReport;
  rolledBack?: boolean;
}

interface OptimizationOperation {
  type: string;
  target: string;
  success: boolean;
  details: any;
  spaceSaved: number;
  duration: number;
}

interface TableOptimizationResult {
  success: boolean;
  details: any;
  spaceSaved: number;
  duration: number;
  improvements: Improvement[];
  warnings: Warning[];
  error?: string;
}

interface IndexOptimizationResult {
  success: boolean;
  details: any;
  spaceSaved: number;
  duration: number;
  improvements: Improvement[];
  warnings: Warning[];
  error?: string;
}

interface RepairResult {
  success: boolean;
  operations: RepairOperation[];
  repairedTables: string[];
  corruptedTables: CorruptedTable[];
  warnings: Warning[];
  error?: string;
}

interface TableCheckResult {
  tableName: string;
  status: 'ok' | 'warning' | 'corrupt' | 'error';
  issues: string[];
  severity: 'none' | 'low' | 'medium' | 'high';
}

interface TableRepairResult {
  success: boolean;
  details: any;
  duration: number;
}
```

### **2. üìä Database Monitoring & Analytics**

#### **Monitoring Service:**
```typescript
export class DatabaseMonitoringService {
  private metricsCollector: MetricsCollector;
  private alertManager: AlertManager;
  private performanceProfiler: PerformanceProfiler;
  private queryAnalyzer: QueryAnalyzer;

  async collectDatabaseMetrics(): Promise<DatabaseMetrics> {
    const metrics: DatabaseMetrics = {
      timestamp: new Date(),
      performance: await this.collectPerformanceMetrics(),
      storage: await this.collectStorageMetrics(),
      connections: await this.collectConnectionMetrics(),
      queries: await this.collectQueryMetrics(),
      replication: await this.collectReplicationMetrics(),
      locks: await this.collectLockMetrics()
    };

    // Check for alerts
    await this.checkMetricAlerts(metrics);

    return metrics;
  }

  private async collectPerformanceMetrics(): Promise<PerformanceMetrics> {
    return {
      qps: await this.getQueriesPerSecond(),
      avgQueryTime: await this.getAverageQueryTime(),
      slowQueries: await this.getSlowQueryCount(),
      cacheHitRatio: await this.getCacheHitRatio(),
      bufferPoolUsage: await this.getBufferPoolUsage(),
      tmpTableUsage: await this.getTmpTableUsage(),
      threadsCached: await this.getThreadsCached(),
      threadsConnected: await this.getThreadsConnected(),
      threadsRunning: await this.getThreadsRunning()
    };
  }

  private async collectStorageMetrics(): Promise<StorageMetrics> {
    return {
      totalSize: await this.getTotalDatabaseSize(),
      dataSize: await this.getTotalDataSize(),
      indexSize: await this.getTotalIndexSize(),
      logSize: await this.getTotalLogSize(),
      freeSpace: await this.getFreeSpace(),
      fragmentation: await this.getAverageFragmentation(),
      tableCount: await this.getTableCount(),
      indexCount: await this.getIndexCount()
    };
  }

  async analyzeSlowQueries(timeRange: DateRange): Promise<SlowQueryAnalysis> {
    const analysis: SlowQueryAnalysis = {
      timeRange,
      totalSlowQueries: 0,
      queries: [],
      patterns: [],
      recommendations: []
    };

    try {
      // Get slow queries from log
      const slowQueries = await this.getSlowQueries(timeRange);
      analysis.totalSlowQueries = slowQueries.length;

      // Analyze each query
      for (const query of slowQueries) {
        const queryAnalysis = await this.analyzeQuery(query);
        analysis.queries.push(queryAnalysis);
      }

      // Identify patterns
      analysis.patterns = await this.identifyQueryPatterns(analysis.queries);

      // Generate recommendations
      analysis.recommendations = await this.generateQueryRecommendations(analysis);

    } catch (error) {
      console.error('Slow query analysis failed:', error);
    }

    return analysis;
  }

  private async analyzeQuery(query: SlowQuery): Promise<QueryAnalysis> {
    const analysis: QueryAnalysis = {
      queryId: query.id,
      sql: query.sql,
      executionTime: query.executionTime,
      lockTime: query.lockTime,
      rowsExamined: query.rowsExamined,
      rowsSent: query.rowsSent,
      executionPlan: null,
      issues: [],
      suggestions: []
    };

    try {
      // Get execution plan
      analysis.executionPlan = await this.getExecutionPlan(query.sql);

      // Analyze execution plan
      const planAnalysis = await this.analyzeExecutionPlan(analysis.executionPlan);
      analysis.issues.push(...planAnalysis.issues);
      analysis.suggestions.push(...planAnalysis.suggestions);

      // Check for common issues
      analysis.issues.push(...await this.checkCommonQueryIssues(query));

    } catch (error) {
      analysis.issues.push({
        type: 'analysis_error',
        description: `Failed to analyze query: ${error.message}`,
        severity: 'medium'
      });
    }

    return analysis;
  }

  async generatePerformanceReport(timeRange: DateRange): Promise<PerformanceReport> {
    const report: PerformanceReport = {
      timeRange,
      summary: await this.generatePerformanceSummary(timeRange),
      metrics: await this.getMetricsHistory(timeRange),
      slowQueries: await this.analyzeSlowQueries(timeRange),
      recommendations: [],
      trends: await this.analyzePerformanceTrends(timeRange)
    };

    // Generate recommendations based on analysis
    report.recommendations = await this.generatePerformanceRecommendations(report);

    return report;
  }
}

interface DatabaseMetrics {
  timestamp: Date;
  performance: PerformanceMetrics;
  storage: StorageMetrics;
  connections: ConnectionMetrics;
  queries: QueryMetrics;
  replication: ReplicationMetrics;
  locks: LockMetrics;
}

interface PerformanceMetrics {
  qps: number; // queries per second
  avgQueryTime: number;
  slowQueries: number;
  cacheHitRatio: number;
  bufferPoolUsage: number;
  tmpTableUsage: number;
  threadsCached: number;
  threadsConnected: number;
  threadsRunning: number;
}

interface SlowQueryAnalysis {
  timeRange: DateRange;
  totalSlowQueries: number;
  queries: QueryAnalysis[];
  patterns: QueryPattern[];
  recommendations: QueryRecommendation[];
}

interface QueryAnalysis {
  queryId: string;
  sql: string;
  executionTime: number;
  lockTime: number;
  rowsExamined: number;
  rowsSent: number;
  executionPlan: ExecutionPlan | null;
  issues: QueryIssue[];
  suggestions: QuerySuggestion[];
}
```

### **3. üßπ Database Cleanup & Maintenance**

#### **Cleanup Service:**
```typescript
export class DatabaseCleanupService {
  private orphanDetector: OrphanDetector;
  private duplicateDetector: DuplicateDetector;
  private logCleaner: LogCleaner;
  private statisticsUpdater: StatisticsUpdater;

  async performCleanup(cleanupConfig: CleanupConfig): Promise<CleanupResult> {
    const result: CleanupResult = {
      success: false,
      operations: [],
      spaceSaved: 0,
      recordsRemoved: 0,
      warnings: []
    };

    try {
      // Clean orphaned records
      if (cleanupConfig.cleanOrphans) {
        const orphanResult = await this.cleanOrphanedRecords(cleanupConfig);
        result.operations.push(orphanResult);
        result.spaceSaved += orphanResult.spaceSaved;
        result.recordsRemoved += orphanResult.recordsRemoved;
      }

      // Remove duplicates
      if (cleanupConfig.removeDuplicates) {
        const duplicateResult = await this.removeDuplicateRecords(cleanupConfig);
        result.operations.push(duplicateResult);
        result.spaceSaved += duplicateResult.spaceSaved;
        result.recordsRemoved += duplicateResult.recordsRemoved;
      }

      // Clean old logs
      if (cleanupConfig.cleanLogs) {
        const logResult = await this.cleanOldLogs(cleanupConfig);
        result.operations.push(logResult);
        result.spaceSaved += logResult.spaceSaved;
        result.recordsRemoved += logResult.recordsRemoved;
      }

      // Update statistics
      if (cleanupConfig.updateStatistics) {
        const statsResult = await this.updateTableStatistics(cleanupConfig);
        result.operations.push(statsResult);
      }

      result.success = result.operations.every(op => op.success);

    } catch (error) {
      result.success = false;
      result.error = error.message;
    }

    return result;
  }

  private async cleanOrphanedRecords(config: CleanupConfig): Promise<CleanupOperation> {
    const operation: CleanupOperation = {
      type: 'orphan_cleanup',
      success: false,
      spaceSaved: 0,
      recordsRemoved: 0,
      duration: 0,
      details: {}
    };

    const startTime = Date.now();

    try {
      // Find orphaned records
      const orphans = await this.orphanDetector.findOrphans(config.tables);
      
      let totalRemoved = 0;
      let totalSpaceSaved = 0;

      for (const orphanGroup of orphans) {
        if (config.dryRun) {
          // Just report what would be removed
          operation.details[orphanGroup.table] = {
            orphanCount: orphanGroup.records.length,
            estimatedSpaceSaved: orphanGroup.estimatedSize
          };
        } else {
          // Actually remove orphans
          const removeResult = await this.removeOrphanedRecords(orphanGroup);
          totalRemoved += removeResult.recordsRemoved;
          totalSpaceSaved += removeResult.spaceSaved;
          
          operation.details[orphanGroup.table] = removeResult;
        }
      }

      operation.recordsRemoved = totalRemoved;
      operation.spaceSaved = totalSpaceSaved;
      operation.success = true;

    } catch (error) {
      operation.success = false;
      operation.error = error.message;
    } finally {
      operation.duration = Date.now() - startTime;
    }

    return operation;
  }

  private async removeDuplicateRecords(config: CleanupConfig): Promise<CleanupOperation> {
    const operation: CleanupOperation = {
      type: 'duplicate_removal',
      success: false,
      spaceSaved: 0,
      recordsRemoved: 0,
      duration: 0,
      details: {}
    };

    const startTime = Date.now();

    try {
      // Find duplicate records
      const duplicates = await this.duplicateDetector.findDuplicates(config.tables, config.duplicateRules);
      
      let totalRemoved = 0;
      let totalSpaceSaved = 0;

      for (const duplicateGroup of duplicates) {
        if (config.dryRun) {
          operation.details[duplicateGroup.table] = {
            duplicateCount: duplicateGroup.duplicates.length,
            estimatedSpaceSaved: duplicateGroup.estimatedSize
          };
        } else {
          const removeResult = await this.removeDuplicates(duplicateGroup, config.keepStrategy);
          totalRemoved += removeResult.recordsRemoved;
          totalSpaceSaved += removeResult.spaceSaved;
          
          operation.details[duplicateGroup.table] = removeResult;
        }
      }

      operation.recordsRemoved = totalRemoved;
      operation.spaceSaved = totalSpaceSaved;
      operation.success = true;

    } catch (error) {
      operation.success = false;
      operation.error = error.message;
    } finally {
      operation.duration = Date.now() - startTime;
    }

    return operation;
  }

  async analyzeStorageUsage(): Promise<StorageUsageAnalysis> {
    const analysis: StorageUsageAnalysis = {
      timestamp: new Date(),
      totalSize: 0,
      tables: [],
      recommendations: []
    };

    try {
      const tables = await this.getAllTables();
      
      for (const tableName of tables) {
        const tableAnalysis = await this.analyzeTableStorage(tableName);
        analysis.tables.push(tableAnalysis);
        analysis.totalSize += tableAnalysis.totalSize;
      }

      // Sort by size
      analysis.tables.sort((a, b) => b.totalSize - a.totalSize);

      // Generate recommendations
      analysis.recommendations = await this.generateStorageRecommendations(analysis);

    } catch (error) {
      console.error('Storage usage analysis failed:', error);
    }

    return analysis;
  }
}

interface CleanupResult {
  success: boolean;
  operations: CleanupOperation[];
  spaceSaved: number;
  recordsRemoved: number;
  warnings: Warning[];
  error?: string;
}

interface CleanupOperation {
  type: string;
  success: boolean;
  spaceSaved: number;
  recordsRemoved: number;
  duration: number;
  details: any;
  error?: string;
}

interface StorageUsageAnalysis {
  timestamp: Date;
  totalSize: number;
  tables: TableStorageAnalysis[];
  recommendations: StorageRecommendation[];
}

interface TableStorageAnalysis {
  tableName: string;
  rowCount: number;
  dataSize: number;
  indexSize: number;
  totalSize: number;
  avgRowLength: number;
  fragmentation: number;
  unusedSpace: number;
  growthTrend: number;
}
```

---

## üé® **Database Management Interface**

### **Database Tools Dashboard:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üóÑÔ∏è Database Management Tools         [Optimize] [Repair] [Analyze] ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚îå‚îÄ Database Health Overview ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ üü¢ Database Status: HEALTHY (Score: 87/100)        ‚îÇ   ‚îÇ
‚îÇ ‚îÇ Last optimization: 2 days ago                      ‚îÇ   ‚îÇ
‚îÇ ‚îÇ                                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ Quick Stats:                                       ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Database Size: 2.3 GB (‚Üë 45MB this week)        ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Tables: 45 ‚Ä¢ Indexes: 127                       ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Queries/sec: 234 avg ‚Ä¢ Slow queries: 12 (24h)   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Cache hit ratio: 94.2%                          ‚îÇ   ‚îÇ
‚îÇ ‚îÇ                                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ Health Issues:                                     ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚ö†Ô∏è 3 tables with fragmentation > 20%              ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚ö†Ô∏è 5 unused indexes detected                       ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚ö†Ô∏è 12 slow queries need optimization              ‚îÇ   ‚îÇ
‚îÇ ‚îÇ                                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ [Run Full Analysis] [Schedule Maintenance]         ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ ‚îå‚îÄ Database Optimization ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ üöÄ Optimization Tools:                             ‚îÇ   ‚îÇ
‚îÇ ‚îÇ                                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ Table Optimization:                                ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ posts: 45% fragmented (Last: Never)             ‚îÇ   ‚îÇ
‚îÇ ‚îÇ   [Optimize] Size: 234MB ‚Ä¢ Rows: 12,456           ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ users: 23% fragmented (Last: 2 days ago)        ‚îÇ   ‚îÇ
‚îÇ ‚îÇ   [Optimize] Size: 89MB ‚Ä¢ Rows: 5,678             ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ comments: 67% fragmented (Last: Never)          ‚îÇ   ‚îÇ
‚îÇ ‚îÇ   [Optimize] Size: 156MB ‚Ä¢ Rows: 23,890           ‚îÇ   ‚îÇ
‚îÇ ‚îÇ                                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ Index Optimization:                                ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ 5 unused indexes (Est. savings: 45MB)           ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ 3 duplicate indexes detected                     ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ 2 missing indexes suggested                      ‚îÇ   ‚îÇ
‚îÇ ‚îÇ                                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ [Optimize All Tables] [Optimize Indexes] [Custom] ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ ‚îå‚îÄ Query Performance Analysis ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ üìä Slow Query Analysis (Last 24h):                 ‚îÇ   ‚îÇ
‚îÇ ‚îÇ                                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ Top Slow Queries:                                  ‚îÇ   ‚îÇ
‚îÇ ‚îÇ 1. SELECT * FROM posts WHERE... (avg: 2.3s)       ‚îÇ   ‚îÇ
‚îÇ ‚îÇ    Executions: 234 ‚Ä¢ Missing index on created_at  ‚îÇ   ‚îÇ
‚îÇ ‚îÇ    [Analyze] [Optimize] [Add Index]               ‚îÇ   ‚îÇ
‚îÇ ‚îÇ                                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ 2. SELECT COUNT(*) FROM comments... (avg: 1.8s)    ‚îÇ   ‚îÇ
‚îÇ ‚îÇ    Executions: 156 ‚Ä¢ Full table scan detected     ‚îÇ   ‚îÇ
‚îÇ ‚îÇ    [Analyze] [Optimize] [Add Index]               ‚îÇ   ‚îÇ
‚îÇ ‚îÇ                                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ 3. UPDATE users SET last_login... (avg: 1.2s)     ‚îÇ   ‚îÇ
‚îÇ ‚îÇ    Executions: 890 ‚Ä¢ Lock contention detected     ‚îÇ   ‚îÇ
‚îÇ ‚îÇ    [Analyze] [Optimize] [Review]                  ‚îÇ   ‚îÇ
‚îÇ ‚îÇ                                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ Query Performance Trends:                          ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Avg query time: ‚Üë 15% vs last week              ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Slow queries: ‚Üë 23% vs last week                ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Cache hit ratio: ‚Üì 2% vs last week              ‚îÇ   ‚îÇ
‚îÇ ‚îÇ                                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ [View All Queries] [Performance Report] [Alerts]  ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ ‚îå‚îÄ Database Maintenance ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ üßπ Maintenance Operations:                         ‚îÇ   ‚îÇ
‚îÇ ‚îÇ                                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ Storage Cleanup:                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Orphaned records: 234 found (Est. 12MB)         ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Duplicate entries: 89 found (Est. 5MB)          ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Old log entries: 1,234 found (Est. 67MB)        ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Unused revisions: 567 found (Est. 23MB)         ‚îÇ   ‚îÇ
‚îÇ ‚îÇ                                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ Database Repair:                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Table integrity: ‚úÖ All tables OK               ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Index consistency: ‚úÖ All indexes OK            ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Foreign key constraints: ‚úÖ All valid           ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Last check: 2 hours ago                         ‚îÇ   ‚îÇ
‚îÇ ‚îÇ                                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ Scheduled Maintenance:                             ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Next optimization: Tonight 2:00 AM              ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Next cleanup: Sunday 3:00 AM                    ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Next backup: Daily 1:00 AM                      ‚îÇ   ‚îÇ
‚îÇ ‚îÇ                                                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ [Run Cleanup] [Check Integrity] [Configure]       ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß **Technical Implementation**

### **API Endpoints:**
```typescript
// Database analysis
GET    /api/tools/database/analyze          // Analyze database
GET    /api/tools/database/health           // Get database health
GET    /api/tools/database/metrics          // Get database metrics
GET    /api/tools/database/storage          // Analyze storage usage

// Database optimization
POST   /api/tools/database/optimize         // Optimize database
POST   /api/tools/database/optimize/tables  // Optimize specific tables
POST   /api/tools/database/optimize/indexes // Optimize indexes
GET    /api/tools/database/optimization/{id} // Get optimization job status

// Database repair
POST   /api/tools/database/repair           // Repair database
POST   /api/tools/database/repair/tables    // Repair specific tables
GET    /api/tools/database/check            // Check database integrity

// Database cleanup
POST   /api/tools/database/cleanup          // Run database cleanup
POST   /api/tools/database/cleanup/orphans  // Clean orphaned records
POST   /api/tools/database/cleanup/duplicates // Remove duplicates
POST   /api/tools/database/cleanup/logs     // Clean old logs

// Query analysis
GET    /api/tools/database/queries/slow     // Get slow queries
POST   /api/tools/database/queries/analyze  // Analyze specific query
GET    /api/tools/database/queries/plan     // Get execution plan

// Database monitoring
GET    /api/tools/database/monitor/performance // Performance metrics
GET    /api/tools/database/monitor/connections // Connection metrics
GET    /api/tools/database/monitor/locks      // Lock information
POST   /api/tools/database/monitor/alerts     // Configure alerts
```

### **Database Schema:**
```sql
-- Database optimization jobs
CREATE TABLE database_optimization_jobs (
  id UUID PRIMARY KEY,
  name VARCHAR(255) NOT NULL,
  type VARCHAR(50) NOT NULL,
  targets JSONB NOT NULL,
  status VARCHAR(50) DEFAULT 'pending',
  progress JSONB DEFAULT '{}',
  results JSONB DEFAULT '{}',
  recommendations JSONB DEFAULT '[]',
  before_snapshot JSONB,
  after_snapshot JSONB,
  rollback_data JSONB,
  started_at TIMESTAMP,
  completed_at TIMESTAMP,
  duration INTEGER, -- milliseconds
  created_by UUID REFERENCES users(id),
  created_at TIMESTAMP DEFAULT NOW()
);

-- Database metrics history
CREATE TABLE database_metrics (
  id UUID PRIMARY KEY,
  timestamp TIMESTAMP DEFAULT NOW(),
  performance_metrics JSONB NOT NULL,
  storage_metrics JSONB NOT NULL,
  connection_metrics JSONB NOT NULL,
  query_metrics JSONB NOT NULL,
  replication_metrics JSONB,
  lock_metrics JSONB
);

-- Slow query log
CREATE TABLE slow_queries (
  id UUID PRIMARY KEY,
  query_hash VARCHAR(64) NOT NULL,
  sql_text TEXT NOT NULL,
  execution_time DECIMAL(10,6) NOT NULL,
  lock_time DECIMAL(10,6) NOT NULL,
  rows_examined BIGINT NOT NULL,
  rows_sent BIGINT NOT NULL,
  timestamp TIMESTAMP DEFAULT NOW(),
  user_host VARCHAR(255),
  database_name VARCHAR(64),
  execution_plan JSONB,
  analyzed BOOLEAN DEFAULT false,
  INDEX idx_query_hash (query_hash),
  INDEX idx_execution_time (execution_time),
  INDEX idx_timestamp (timestamp)
);

-- Database alerts
CREATE TABLE database_alerts (
  id UUID PRIMARY KEY,
  alert_type VARCHAR(50) NOT NULL,
  metric_name VARCHAR(100) NOT NULL,
  threshold_value DECIMAL(15,6) NOT NULL,
  current_value DECIMAL(15,6) NOT NULL,
  severity VARCHAR(20) NOT NULL,
  status VARCHAR(20) DEFAULT 'active',
  triggered_at TIMESTAMP DEFAULT NOW(),
  resolved_at TIMESTAMP,
  message TEXT,
  metadata JSONB DEFAULT '{}'
);

-- Database cleanup history
CREATE TABLE database_cleanup_history (
  id UUID PRIMARY KEY,
  cleanup_type VARCHAR(50) NOT NULL,
  started_at TIMESTAMP DEFAULT NOW(),
  completed_at TIMESTAMP,
  duration INTEGER, -- milliseconds
  operations JSONB NOT NULL,
  space_saved BIGINT DEFAULT 0,
  records_removed BIGINT DEFAULT 0,
  success BOOLEAN DEFAULT false,
  error_message TEXT
);

-- Table analysis cache
CREATE TABLE table_analysis_cache (
  id UUID PRIMARY KEY,
  table_name VARCHAR(255) NOT NULL,
  schema_name VARCHAR(255) NOT NULL,
  analysis_data JSONB NOT NULL,
  created_at TIMESTAMP DEFAULT NOW(),
  expires_at TIMESTAMP NOT NULL,
  UNIQUE(table_name, schema_name)
);

-- Indexes for performance
CREATE INDEX idx_database_optimization_jobs_status ON database_optimization_jobs(status);
CREATE INDEX idx_database_optimization_jobs_created_at ON database_optimization_jobs(created_at);
CREATE INDEX idx_database_metrics_timestamp ON database_metrics(timestamp);
CREATE INDEX idx_database_alerts_status ON database_alerts(status);
CREATE INDEX idx_database_alerts_triggered_at ON database_alerts(triggered_at);
CREATE INDEX idx_database_cleanup_history_cleanup_type ON database_cleanup_history(cleanup_type);
CREATE INDEX idx_table_analysis_cache_expires_at ON table_analysis_cache(expires_at);
```

---

## üîó **Related Documentation**

- **[Backup & Restore](./backup.md)** - Database backup integration
- **[Import/Export](./import-export.md)** - Database migration tools
- **[System Diagnostics](./diagnostics.md)** - Database health monitoring
- **[System Performance](../07_system/performance.md)** - Performance optimization
- **[System Health](../07_system/health.md)** - Health monitoring integration

---

**Last Updated:** 2024-01-09  
**Version:** 2.0  
**Status:** Active
